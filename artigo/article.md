# Beyond the Clouds: Innovative Strategies for Optimization in Legacy Infrastructures

Arthur Nisa
Esther Hikari
Henrique Godoy
Thomaz Klifson
Marcos Teixeira

Inteli

## Abstract

Exploring the urgency of modernizing legacy systems, this study proposes an integrated and strategic approach, highlighting the optimization of database access as essential to enhancing user experience and operational efficiency. Introducing a pioneering solution, an intermediary architecture like intelligent caching seeks not only to reduce response time but also to offer flexibility in data management. Additionally, the importance of a holistic view in modernizing legacy systems and optimizing resources in cloud environments is emphasized, aligning with the objective of strengthening organizations' competitiveness in a dynamic business landscape.

## 1 Introduction

In the contemporary digital era, where interconnectivity advances ceaselessly and services evolve constantly, understanding cloud computing concepts becomes an urgent necessity [1]. The advent of these environments, inaugurated by Amazon's pioneering launch in the recent past, resonates with the wisdom that every solution may trigger new challenges. In this context, effectiveness in problem-solving and value creation for companies are intrinsically linked to software architecture and implementation. As large corporations integrate a variety of services, complexity exponentially grows, exacerbated by the presence of legacy systems [2] and system integrations due to successive acquisitions of other companies. This multiplicity of elements demands efficient orchestration, lest it compromises system operability and performance. It is in this scenario that the problem addressed in this article takes shape, in collaboration with the telecommunications company Vivo: the creation of a scalable application aiming to optimize access to legacy databases, whose current response time negatively impacts user experience [3] and company operational agility.

In this article, we explore an innovative approach to tackle the challenges of legacy infrastructures, highlighting not only the need for optimization but also the importance of a strategic and integrated vision to deal with such systems in a rapidly evolving technological context. We will present a detailed analysis of the motivation behind the initiative, the proposed solution, and its implications both for Vivo and for the broader landscape of companies with legacy systems.

Given the magnitude of Vivo's customer base and the urgency of this challenge, reducing data access time constitutes not only a technical imperative but also a significant opportunity to enhance user experience and drive advancements in the telecommunications sector. By improving interaction with Vivo's services, this initiative fosters substantial modernization in this vital segment of the economy, reflecting tangible gains for the company and an enhanced user experience at all touchpoints, from existing customers to potential conversions through advertising actions [4]. This holistic approach aims not only to improve the company's operational efficiency but also to strengthen its competitive position in the market.

The proposed solution to address this issue consists of implementing an intermediary architecture that acts as a data storage layer, akin to intelligent caching. By adopting this approach, key access channels will be able to directly query this intermediary structure, avoiding the need to traverse the entire legacy infrastructure, resulting in a substantial improvement in response time. It is important to emphasize that full storage of legacy data is not viable in terms of infrastructure and costs, preferring the strategy of storing a portion of the most accessed data. Additionally, the introduction of an intelligent mechanism in this architecture will allow for optimizing the use of the database, dynamically adjusting the amount of stored data according to demand, and incorporating periodic updates based on probabilistic analyses. This approach not only benefits the project at hand with Vivo but also has the potential to positively impact other companies with legacy systems, offering a scalable and adaptable solution to common challenges faced in modernizing legacy technological infrastructures.

## 2 Related Work

Modernizing legacy systems represents a primary challenge for contemporary organizations, as documented by studies such as "A Guidance to Legacy Systems Modernization" [5]. These systems, though essential for business operations, often encounter significant technical obstacles, especially due to rapid technological evolution. The study emphasizes the need for a holistic approach that takes into account not only the technical aspects but also the organization's strategic objectives and the constantly changing demands of the market. A tangible example of these challenges is examined in the article "Challenges in migrating legacy software systems to the cloud—an empirical study" [6], which highlights the complexities and costs associated with migrating legacy systems to the cloud, underscoring the importance of adequate understanding and preparation to mitigate potential failures in the process. The integrated analysis of these studies underscores the importance of a holistic approach that encompasses not only the technical aspects of modernization but also strategic and organizational considerations.

The issue of cost optimization in cloud environments gains additional prominence when considering evidence of considerable underutilization and resource waste in organizations' IT infrastructures, as discussed in the study "Cloud Cost Optimization: Finding Unused Cloud Resources Using Machine Learning and Heuristics" [7]. This study investigated methods for automatically identifying unused and underutilized resources in the cloud, employing unsupervised learning techniques and heuristics on monitored metrics and metadata. The results highlighted the effectiveness of these methods in accurately detecting such resources, underscoring the need for further research to promote efficient cloud resource usage. Furthermore, given the complexity of challenges related to resource optimization in cloud environments, it is important to emphasize the fundamental role of algorithms in solving these problems. The article "Algorithms for Cloud Computing" [8] provides a broad overview of how algorithms can be applied in various areas within cloud systems, from resource planning for future demand to equitable resource allocation and the development of load balancing algorithms. This work highlights the importance of using mathematical modeling, optimization, machine learning, and stochastic processes in designing algorithms for cloud systems, demonstrating how advances in this area can significantly contribute to the efficiency and performance of cloud computing environments.

To address the issue of cloud system optimization, it is crucial to consider not only the detection of unused resources but also the evaluation of cloud providers' performance. As evidenced in the study "Response Time for Cloud Computing Providers" [9], selecting cloud providers based on performance and reliability is critical, especially for critical business applications and sensitive information. Moreover, understanding the performance of cloud infrastructure is essential for the effective use of cloud services. For example, the demonstration that the "Extra large high CPU" instance type has the best performance stability. Therefore, response time can be an important parameter in service level agreements, but it is crucial to improve response time stability before signing any agreement between cloud provider and user. These findings highlight the importance of a careful approach in selecting and utilizing resources in cloud environments, aiming for efficient and reliable management of these systems.

In a broader landscape, spanning from inherent challenges in migrating legacy systems to strategies for cost optimization in cloud environments, and even encompassing the crucial evaluation of cloud providers' performance, the central role of efficient and economical management of cloud resources becomes undeniable as one of the fundamental pillars for the success of contemporary organizations. In this context, improving cloud system response time emerges as a key piece in this intricate puzzle of efficiency and competitiveness, echoing directly with the essential objectives outlined in this article. The demand for precise and optimized management of cloud resources, emphasized in the referenced studies, significantly converges with the approach proposed in this work, which focuses on optimizing access to legacy databases at Vivo. Moreover, enhancing cloud system response time is a shared priority, considering its importance both in enhancing user experience and in elevating the company's competitiveness in the market. The analysis of advances in detecting underutilized resources, the careful selection of cloud providers, and the improvement of response time stability, as discussed in the referenced studies, clearly demonstrate the need for a holistic approach that encompasses not only technical aspects but also strategic considerations, aiming to ensure operational efficiency and strengthen

### 3 Materials and Methods

We initiated our study by conducting an in-depth analysis of the requirements in close collaboration with the Vivo team. This process involved not only a thorough understanding of the challenges faced by the company in accessing legacy databases but also the simulation of operational and front-end environments. Such an approach allowed for a closer immersion into the experiences of Vivo employees, ensuring a holistic and detailed understanding of the problem at hand.

To simulate the functional requirements of Vivo systems, such as user authentication, Vivo Mobile, and Vivo Fiber, a specific architecture was implemented. This architecture involved the development of systems in TypeScript for the integration of three microservices, using the Kotlin framework for Vivo Fiber and Vivo Mobile services, along with the implementation of intelligent caching functionalities in TypeScript, employing the fast key-value database Redis. All other databases were configured in PostgreSQL. It is noteworthy that the primary objective was the precise simulation of Vivo microservices, focusing optimization on the intelligent cache system through a refined approach in both code and framework selection.

The cloud architecture was meticulously implemented using Virtual Private Cloud (VPC), aiming at isolating the infrastructure in a virtual private network to ensure a controlled and secure environment. The microservices were run on EC2 instances, configured with a high level of sophistication, including the use of Docker and Kubernetes to facilitate vertical scalability, considering the volatility of demand in Vivo systems. Data storage was managed by an Amazon RDS PostgreSQL instance, providing a durable and scalable solution for system data. Furthermore, the intelligent cache system was implemented using a Redis memory database, ensuring fast and efficient data handling in real-time.

In the implementation of the intelligent cache, a meticulous logic was adopted for data insertion, editing, and removal, aiming to maintain their consistency. For this purpose, a unique identifying key (ID) was employed, ensuring that, in case of editing, a new data would not be mistakenly inserted and, moreover, preserving the integrity of the data that should be altered. In general terms, the operational flow consists of checking the existence of data in the cache: if present, the data is immediately returned; otherwise, a query to the legacy database is performed. Depending on the state of the database, the data is inserted or not into the cache before being sent as a response to the user.

Due to economic limitations preventing the full transfer of the database to the cache, a maximum size is imposed on the cached database. In this scenario, if it is necessary to insert new data with a full cache, a probability-based strategy is employed. For this, the following formula is used:

f(x | \mu, \sigma^2, t) = \frac{\frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}}{\log(t)}

This approach considers that each data follows a normal distribution, taking into account the number of accesses to the data and the time elapsed since its inclusion in the database. Consequently, the longer the data's period of inactivity, the lower its probability of being chosen. A dedicated column for the number of times a data has been updated is incorporated into this logic, providing the cache with intelligent storage capability, prioritizing data of greater relevance based on probabilistic criteria. Thus, this approach makes the cache an intelligent tool, capable of optimizing resource usage, reducing reliance on traditional databases, and significantly improving response time, which is advantageous for Vivo in economic and operational terms.

To ensure the application's quality and scalability, we adopted the K6 tool, which allows for the simulation of high-traffic scenarios through JavaScript scripts. This approach allowed us to assess the application's performance during periods of high load, as well as to collect precise metrics on the efficiency of the implemented infrastructure. Such metrics were essential to identify any bottlenecks and promote application optimization, thus ensuring its compliance with the quality and performance standards required by the Vivo operating environment.

### 4 Results 

The core of the project lay in reducing the response time of Vivo's legacy systems without disturbing their integrity. Although the idea of adding an additional structure may seem contradictory to system optimization, several tests were conducted, both using the system without the application of intelligent caching and employing it. When analyzing the systems' performance under both contexts, considering the routes within the scope of functional requirements, it was found that the average response time without intelligent caching was 0.614 seconds. In contrast, with the incorporation of intelligent caching, this average time decreased to 0.213 seconds. It is important to note that the relationship between the average response times with and without intelligent caching presents a statistically insignificant correlation, suggesting that the expectation of a 3-fold performance improvement when employing intelligent caching may be overly optimistic. However, even if the average response time after the implementation of intelligent caching does not reach the 0.213 seconds observed in the tests, it is plausible to infer that it will be significantly faster than the current response times, which can reach up to 30 seconds in the worst-case scenario. These results demonstrate that the introduction of intelligent caching has the potential to provide substantial improvements in response time not only in Vivo's legacy systems but also in other existing legacy systems, representing a significant advancement in terms of efficiency and operational performance.

Furthermore, additional optimizations in the system are possible, including the adoption of strategies such as Dragonfly. Dragonfly, a highly efficient and scalable in-memory storage framework, surpasses Redis in terms of access speed and ability to handle large volumes of data. Its distributed and message-oriented architecture offers significant advantages in high-traffic scenarios and intensive demand for fast data access. Additionally, the implementation of an isolated microservice dedicated to updating the probabilities associated with stored data is proposed. This microservice, operating asynchronously and independently, reduces the waits associated with probability updates, ensuring a more agile and consistent response time for user queries. Furthermore, the introduction of dynamic sizing for databases can be explored, allowing the cache size to adjust dynamically based on parameters such as temporary volatility and access demand. Another potentially beneficial approach is the application of data encryption and compression techniques. By encrypting stored data and compressing it using efficient compression algorithms, it is possible to significantly reduce data size, resulting in faster response times due to the decrease in the volume of data to be transferred and processed. These combined strategies have the potential to further enhance the performance and operational efficiency of the system, offering faster and more consistent responses to users while optimizing the use of available storage and processing resources.

### 5 References

[1] Armbrust, M., Fox, A., Griffith, R., Joseph, A., Katz, R., Konwinski, A., et al. (2009). Above the Clouds: A Berkeley View of Cloud
Computing. EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2009-28. 

[2] Assunção, Wesley. (2021). Contemporary Software Modernization: Perspectives and Challenges to Deal with Legacy Systems. 10.13140/RG.2.2.25176.42243. 

[3] Willermark, Sara & Pantic, Nikola & Pehrson, Hannah. (2021). Subjectively Experienced Time and User Satisfaction: An Experimental Study of Progress Indicator Design in Mobile Application. 10.24251/HICSS.2021.543. 

[4] Black Friday traffic takes down Sears.com. Associated Press (November 2008).

[5] Abu Bakar, Humairath KM, et al. “A Guidance to Legacy Systems Modernization”. International Journal on Advanced Science, Engineering and Information Technology, vol. 10, no. 3, June 2020, pp. 1042-50, doi:10.18517/ijaseit.10.3.10265.

[6] Mahdi Fahmideh Gholami, Farhad Daneshgar, Ghassan Beydoun, Fethi Rabhi,
Challenges in migrating legacy software systems to the cloud — an empirical study,
Information Systems, Volume 67, 2017, Pages 100-113, ISSN 0306-4379,

[7] Ericsson, Sonja. "Cloud cost optimization : Finding unused cloud resources using machine learning and heuristics." Thesis, KTH, Skolan för elektroteknik och datavetenskap (EECS), 2020. http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-289654.

[8] Paschos Georgios. Algorithms for Cloud Computing. 2021. https://paschos.net/wp-content/uploads/2021/02/Paschos_cloud_computing_part1.pdf

[9] Alhamad, Mohammed & Dillon, Tharam & wu, Chen & Chang, Elizabeth. (2010). Response time for cloud computing providers. 603-606. 10.1145/1967486.1967579.
