# Além das Nuvens: Estratégias Inovadoras para Otimização em Infraestruturas Legadas

Arthur Nisa
Esther Hikari
Henrique Godoy
Thomaz Klifson
Marcos Teixeira

Inteli

## Resumo

Explorando a urgência da modernização de sistemas legados, este estudo propõe uma abordagem integrada e estratégica, destacando a otimização do acesso a bases de dados como essencial para aprimorar a experiência do usuário e a eficiência operacional. Introduzindo uma solução pioneira, uma arquitetura intermediária como cache inteligente, busca-se não apenas reduzir o tempo de resposta, mas também oferecer flexibilidade na gestão de dados. Além disso, salienta-se a importância de uma visão holística na modernização de sistemas legados e na otimização de recursos em ambientes de nuvem, alinhando-se ao objetivo de fortalecer a competitividade das organizações em um cenário empresarial dinâmico.

## 1. Introdução

Na era digital contemporânea, em que a interconexão avança sem cessar e os serviços evoluem constantemente, a compreensão dos conceitos de computação em nuvem torna-se uma necessidade premente, conforme documentado por ARMBRUST, Michael (2009) [1]. O advento desses ambientes, inaugurado pelo lançamento pioneiro da Amazon em um passado recente, ressoa a sabedoria de que toda solução pode desencadear novos desafios. Neste contexto, a eficácia na resolução de problemas e a criação de valor para as empresas estão intrinsecamente ligadas à arquitetura e implementação de software. À medida que grandes corporações integram uma diversidade de serviços, a complexidade cresce exponencialmente, agravada pela presença de sistemas legados, como visto por ASSUNÇÃO, Wesley (2021) [2] e integrações de sistemas devido a aquisições sucessivas de outras empresas. Esta multiplicidade de elementos exige uma orquestração eficiente, sob pena de comprometer a operacionalidade e desempenho dos sistemas. É neste cenário que se delineia o problema abordado neste artigo, em colaboração com a empresa de telecomunicações Vivo: a criação de uma aplicação escalável com o objetivo de otimizar o acesso a bases de dados legadas, cujo tempo de resposta atual impacta negativamente na experiência do usuário, conforme evidenciado por WILLERMARK, Sara (2021) [3] e na agilidade operacional da empresa.

Neste artigo, exploraremos uma abordagem inovadora para enfrentar os desafios de infraestruturas legadas, destacando não apenas a necessidade de otimização, mas também a importância de uma visão estratégica e integrada para lidar com tais sistemas em um contexto de rápida evolução tecnológica. Apresentaremos uma análise detalhada da motivação por trás da iniciativa, a solução proposta e suas implicações tanto para a Vivo quanto para o cenário mais amplo das empresas com sistemas legados.

Dada a magnitude da base de clientes da Vivo e a urgência deste desafio, a redução do tempo de acesso aos dados constitui não apenas um imperativo técnico, mas também uma oportunidade significativa para aprimorar a experiência do usuário e impulsionar os avanços no setor de telecomunicações. Ao melhorar a interação com os serviços da Vivo, esta iniciativa promove uma modernização substancial neste segmento vital da economia, refletindo em ganhos tangíveis para a empresa e uma experiência do usuário aprimorada em todos os pontos de contato, desde clientes existentes até potenciais conversões através de ações publicitárias, conforme registrado por Associated Press. (2008) [4]. Esta abordagem holística busca não só melhorar a eficiência operacional da empresa, mas também fortalecer sua posição competitiva no mercado.

A solução proposta para abordar este problema consiste na implementação de uma arquitetura intermediária que atue como uma camada de armazenamento de dados, semelhante a um cache inteligente. Ao adotar esta abordagem, os principais barramentos de acesso poderão consultar diretamente esta estrutura intermediária, evitando a necessidade de percorrer toda a infraestrutura legada, o que resultará em uma melhoria substancial no tempo de resposta. É importante ressaltar que a armazenagem integral dos dados legados não é viável em termos de infraestrutura e custos, sendo preferível a estratégia de armazenar uma parcela dos dados mais acessados. Adicionalmente, a introdução de um mecanismo inteligente nesta arquitetura permitirá otimizar o uso do banco de dados, ajustando dinamicamente a quantidade de dados armazenados de acordo com a demanda, além de incorporar atualizações periódicas com base em análises probabilísticas. Esta abordagem não apenas beneficia o projeto em questão com a Vivo, mas também tem potencial para impactar positivamente outras empresas com sistemas legados, oferecendo uma solução escalável e adaptável para os desafios comuns enfrentados na modernização de infraestruturas tecnológicas legadas.

## 2. Trabalhos Relacionados

A modernização de sistemas legados representa um desafio primordial para as organizações contemporâneas, conforme documentado por ABU BAKAR, Humairath KM (2005) [5]. Estes sistemas, embora essenciais para operações comerciais, frequentemente se deparam com obstáculos técnicos significativos, especialmente devido à rápida evolução tecnológica. O estudo enfatiza a necessidade de uma abordagem holística que leve em conta não apenas os aspectos técnicos, mas também os objetivos estratégicos da organização e as demandas em constante mutação do mercado. Um exemplo tangível desses desafios é examinado no artigo de FAHMIDEH GHOLAMI, Mahdi (2017) [6], que evidencia as complexidades e os custos associados à migração de sistemas legados para a nuvem, sublinhando a importância de uma compreensão e preparação adequadas para mitigar possíveis falhas no processo. A análise integrada desses estudos ressalta a importância de uma abordagem holística que abarque não apenas os aspectos técnicos da modernização, mas também as considerações estratégicas e organizacionais.

A questão da otimização de custos em ambientes de nuvem ganha destaque adicional quando consideramos a evidência de uma considerável subutilização e desperdício de recursos nas infraestruturas de TI das organizações, conforme discutido no estudo de ERICSSON, Sonja (2020)[7]. Este estudo investigou métodos para identificar automaticamente recursos não utilizados e pouco utilizados na nuvem, empregando técnicas de aprendizado não supervisionado e heurísticas em métricas e metadados monitorados. Os resultados destacaram a eficácia desses métodos na detecção precisa desses recursos, sublinhando a necessidade de pesquisas adicionais para promover o uso eficiente de recursos em nuvem. Ademais, dada a complexidade dos desafios relacionados à otimização de recursos em ambientes de nuvem, é importante ressaltar o papel fundamental dos algoritmos na resolução desses problemas. O artigo de GEORGIOS, Paschos (2021) [8] fornece uma visão ampla de como os algoritmos podem ser aplicados em várias áreas dentro de sistemas em nuvem, desde o planejamento de recursos para demanda futura até a alocação equitativa de recursos e o desenvolvimento de algoritmos de balanceamento de carga. Este trabalho destaca a importância da utilização de modelagem matemática, otimização, aprendizado de máquina e processos estocásticos na concepção de algoritmos para sistemas em nuvem, demonstrando como os avanços nessa área podem contribuir significativamente para a eficiência e o desempenho dos ambientes de computação em nuvem.

Para abordar a questão da otimização de sistemas em nuvem, é crucial considerar não apenas a detecção de recursos não utilizados, mas também a avaliação do desempenho dos provedores de nuvem. Como evidenciado no estudo de ALHAMAD, Mohammed (2010) [9], a seleção de provedores de nuvem com base no desempenho e na confiabilidade é crítica, especialmente para aplicações empresariais críticas e informações sensíveis. Além disso, compreender o desempenho da infraestrutura de nuvem é essencial para o uso eficaz dos serviços em nuvem. Por exemplo, a demonstração que o tipo de instância "Extra large high CPU" possui a melhor estabilidade de desempenho. Portanto, o tempo de resposta pode ser um parâmetro importante nos acordos de nível de serviço, mas é crucial melhorar a estabilidade do tempo de resposta antes de assinar qualquer acordo entre provedor de nuvem e usuário. Essas conclusões destacam a importância de uma abordagem criteriosa na seleção e utilização de recursos em ambientes de nuvem, visando uma gestão eficiente e confiável desses sistemas.

Em um panorama mais abrangente, que abarca desde os desafios inerentes à migração de sistemas legados até as estratégias voltadas para a otimização de custos em ambientes de nuvem, e ainda passando pela crucial avaliação do desempenho dos provedores de nuvem, torna-se inegável a centralidade da gestão eficiente e econômica dos recursos em nuvem como um dos pilares fundamentais para o sucesso das organizações contemporâneas. Nesse contexto, o aprimoramento do tempo de resposta dos sistemas em nuvem emerge como uma peça chave neste intricado quebra-cabeça de eficiência e competitividade, ecoando diretamente com os objetivos essenciais delineados neste artigo. A demanda por uma gestão precisa e otimizada dos recursos em nuvem, enfatizada nos estudos referenciados, converge de maneira significativa com a abordagem proposta neste trabalho, que se concentra na otimização do acesso a bases de dados legadas na empresa Vivo. Ademais, o melhoramento do tempo de resposta dos sistemas em nuvem é uma prioridade compartilhada, considerando sua importância tanto para aprimorar a experiência do usuário quanto para elevar a competitividade da empresa no mercado. A análise dos avanços em detecção de recursos subutilizados, a seleção criteriosa de provedores de nuvem e o aprimoramento da estabilidade do tempo de resposta, conforme discutido nos estudos referenciados, evidenciam de forma clara a necessidade de uma abordagem holística, que englobe não apenas os aspectos técnicos, mas também os estratégicos, visando assegurar a eficiência operacional e fortalecer a posição competitiva das organizações em um cenário empresarial dinâmico e altamente concorrido.

## 3. Materias e Métodos

Iniciamos nosso estudo realizando uma análise aprofundada dos requisitos em estreita colaboração com a equipe da Vivo. Este processo envolveu não apenas a compreensão exaustiva dos desafios enfrentados pela empresa no acesso às bases de dados legadas, mas também a simulação de ambientes operacionais e de front-end. Tal abordagem permitiu uma imersão mais próxima das experiências dos funcionários da Vivo, garantindo uma compreensão holística e detalhada do problema em questão.

Para simular os requisitos funcionais dos sistemas da Vivo, como autenticação de usuário, Vivo Móvel e Vivo Fibra, foi implementada uma arquitetura específica. Esta arquitetura envolveu o desenvolvimento de sistemas em TypeScript para a integração de três microserviços, utilizando o framework Kotlin para os serviços de Vivo Fibra e Vivo Móvel, além da implementação das funcionalidades de cache inteligente em TypeScript, com o emprego do banco de dados chave-valor rápido Redis. Todos os demais bancos de dados foram configurados em PostgreSQL. Ressalta-se que o objetivo primordial foi a simulação precisa dos microserviços da Vivo, concentrando a otimização no sistema de cache inteligente, através de uma abordagem refinada tanto no código quanto na seleção de frameworks.

A arquitetura em nuvem foi meticulosamente implementada utilizando Virtual Private Cloud (VPC), visando o isolamento da infraestrutura em uma rede privada virtual para garantir um ambiente controlado e seguro. Os microserviços foram executados em instâncias EC2, configuradas com alto nível de sofisticação, incluindo o uso de Docker e Kubernetes para facilitar a escalabilidade vertical, levando em consideração a volatilidade da demanda nos sistemas da Vivo. O armazenamento de dados foi gerenciado por uma instância PostgreSQL do Amazon RDS, proporcionando uma solução duradoura e escalável para os dados do sistema. Ademais, o sistema de cache inteligente foi implementado utilizando um banco de dados de memória Redis, garantindo uma rápida e eficiente manipulação dos dados em tempo real.

Na implementação do cache inteligente, adotou-se uma lógica meticulosa para a inserção, edição e remoção de dados, visando manter a consistência dos mesmos. Para tal desiderato, foi empregada uma chave identificadora única (ID), garantindo que, em caso de edição, um novo dado não seja erroneamente inserido e, ademais, preservando a integridade do dado que deveria ser alterado. Em linhas gerais, o fluxo operacional consiste na verificação da existência do dado no cache: se presente, o dado é imediatamente retornado; caso contrário, uma consulta ao banco de dados legado é realizada. Dependendo do estado do banco de dados, o dado é inserido ou não no cache antes de ser enviado como resposta ao usuário.

Devido a limitações econômicas que impedem a transferência integral do banco de dados para o cache, um tamanho máximo é imposto ao banco de dados em cache. Nesse cenário, caso seja necessário inserir um novo dado com o cache completo, uma estratégia baseada em probabilidades é empregada. Para isso, utiliza-se a seguinte fórmula:

f(x | \mu, \sigma^2, t) = \frac{\frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}}{\log(t)}

Essa abordagem considera que cada dado segue uma distribuição normal, levando em conta o número de acessos ao dado e o tempo decorrido desde a sua inclusão no banco de dados. Consequentemente, quanto maior o período de inatividade do dado, menor será a sua probabilidade de ser escolhido. Uma coluna dedicada ao número de vezes que um dado foi atualizado é incorporada nessa lógica, conferindo ao cache uma capacidade de armazenamento inteligente, priorizando dados de maior relevância com base em critérios probabilísticos. Assim, esse enfoque torna o cache uma ferramenta inteligente, capaz de otimizar o uso de recursos, reduzindo a dependência de bancos de dados tradicionais e melhorando significativamente o tempo de resposta, o que se revela vantajoso para a Vivo em termos econômicos e operacionais.

## 4. Resultados

Para assegurar a qualidade da aplicação e sua capacidade de escalabilidade, adotamos a ferramenta K6, que possibilita a simulação de cenários de tráfego intenso por meio de scripts em JavaScript. Esta abordagem permitiu avaliar o desempenho da aplicação em momentos de carga elevada, além de coletar métricas precisas da eficiência da infraestrutura implementada. Tais métricas foram essenciais para identificar eventuais gargalos e promover a otimização da aplicação, garantindo assim sua adequação aos padrões de qualidade e performance exigidos pelo ambiente de operação da Vivo.

O cerne do projeto residia na redução do tempo de resposta dos sistemas legados da Vivo, sem perturbar sua integridade. Embora a ideia de adicionar uma estrutura adicional possa parecer contraditória à otimização do sistema, foram conduzidos diversos testes, tanto utilizando o sistema sem a aplicação do cache inteligente quanto empregando-o. Ao analisar o desempenho dos sistemas sob ambos os contextos, considerando as rotas no âmbito dos requisitos funcionais, constatou-se que o tempo médio de resposta sem o cache inteligente foi de 0.614 segundos. Em contrapartida, com a incorporação do cache inteligente, esse tempo médio diminuiu para 0.213 segundos.É importante ressaltar que a relação entre os tempos médios de resposta com e sem o cache inteligente apresenta uma correlação pouco significativa, sugerindo que a expectativa de uma melhoria de desempenho de 3 vezes ao empregar o cache inteligente pode ser excessivamente otimista. No entanto, mesmo que o tempo médio de resposta após a implementação do cache inteligente não atinja os 0.213 segundos observados nos testes, é plausível inferir que será significativamente mais rápido do que os tempos de resposta atuais, que podem chegar a 30 segundos no pior cenário. Esses resultados evidenciam que a introdução do cache inteligente tem o potencial de proporcionar melhorias substanciais no tempo de resposta não apenas nos sistemas legados da Vivo, quantos em outros sistemas legados existentes, representando um avanço significativo em termos de eficiência e desempenho operacional.

Além disso, são possíveis otimizações adicionais no sistema, incluindo a adoção de estratégias como o Dragonfly. O Dragonfly, uma estrutura de armazenamento em memória altamente eficiente e escalável, supera o Redis em termos de velocidade de acesso e capacidade de manipulação de grandes volumes de dados. Sua arquitetura distribuída e orientada a mensagem oferece vantagens significativas em cenários de alto tráfego e demanda intensiva por acesso rápido a dados. Adicionalmente, propõe-se a implementação de um microserviço isolado dedicado à atualização das probabilidades associadas aos dados armazenados. Esse microserviço, operando de forma assíncrona e independente, reduz as esperas associadas à atualização das probabilidades, garantindo um tempo de resposta mais ágil e consistente para as consultas dos usuários. Além disso, a introdução de um tamanho dinâmico para os bancos de dados pode ser explorada, permitindo que o tamanho do cache se ajuste dinamicamente com base em parâmetros como volatilidade temporária e demanda de acesso. Outra abordagem potencialmente benéfica é a aplicação de técnicas de criptografia e compressão de dados. Ao criptografar os dados armazenados e compactá-los utilizando algoritmos eficientes de compressão, é possível reduzir significativamente o tamanho dos dados, resultando em tempos de resposta mais rápidos devido à diminuição do volume de dados a ser transferido e processado. Essas estratégias combinadas têm o potencial de aprimorar ainda mais o desempenho e a eficiência operacional do sistema, oferecendo respostas mais rápidas e consistentes aos usuários, ao mesmo tempo em que otimizam o uso de recursos de armazenamento e processamento disponíveis.

### 5. Conclusão

Em suma, a parceria com a empresa de telecomunicações Vivo permitiu a concepção e implementação bem-sucedida de uma solução inovadora para otimização de sistemas legados. Ao introduzir uma arquitetura intermediária como cache inteligente, demonstramos não apenas a viabilidade técnica, mas também o potencial econômico e operacional dessa abordagem. Os resultados obtidos destacaram claramente a eficácia do cache inteligente na melhoria do tempo de resposta dos sistemas legados da Vivo. Além disso, identificamos diversas oportunidades de otimização e aprimoramento que podem ser exploradas no futuro. Este trabalho não só endereça as demandas específicas da Vivo, mas também oferece insights valiosos para o panorama mais amplo das empresas com sistemas legados, preparando-as para os desafios e oportunidades do mercado empresarial em constante evolução.

### 6. Referências

[1] ARMBRUST, Michael et al. Above the clouds: A Berkeley view of cloud computing. Vol. 17. Technical Report UCB/EECS-2009-28, EECS Department, University of California, Berkeley, 2009.

[2] ASSUNÇÃO, Wesley et al. Contemporary Software Modernization: Perspectives and Challenges to Deal with Legacy Systems. 10.13140/RG.2.2.25176.42243, 2021.

[3] WILLERMARK, Sara et al. Subjectively Experienced Time and User Satisfaction: An Experimental Study of Progress Indicator Design in Mobile Application. 10.24251/HICSS.2021.543, 2021.

[4] Associated Press. Black Friday traffic takes down Sears.com. November 2008.

[5] ABU BAKAR, Humairath KM et al. A Guidance to Legacy Systems Modernization. International Journal on Advanced Science, Engineering and Information Technology, vol. 10, no. 3, June 2020, pp. 1042-50, doi:10.18517/ijaseit.10.3.10265.

[6] FAHMIDEH GHOLAMI, Mahdi et al. Challenges in migrating legacy software systems to the cloud — an empirical study. Information Systems, Volume 67, 2017, Pages 100-113, ISSN 0306-4379.

[7] ERICSSON, Sonja. Cloud cost optimization : Finding unused cloud resources using machine learning and heuristics. Thesis, KTH, Skolan för elektroteknik och datavetenskap (EECS), 2020. http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-289654.

[8] GEORGIOS, Paschos. Algorithms for Cloud Computing. 2021. https://paschos.net/wp-content/uploads/2021/02/Paschos_cloud_computing_part1.pdf.

[9] ALHAMAD, Mohammed et al. Response time for cloud computing providers. 603-606, 2010. doi:10.1145/1967486.1967579.